<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Memo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-01-08T08:39:21.680Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Sibyl K</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Zotero使用简明指南</title>
    <link href="http://yoursite.com/2020/01/08/%E2%80%9CZotero%E4%BD%BF%E7%94%A8%E7%AE%80%E6%98%8E%E6%8C%87%E5%8D%97%E2%80%9D/"/>
    <id>http://yoursite.com/2020/01/08/“Zotero使用简明指南”/</id>
    <published>2020-01-08T08:22:23.000Z</published>
    <updated>2020-01-08T08:39:21.680Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="下载与基本设置"><a href="#下载与基本设置" class="headerlink" title="下载与基本设置"></a>下载与基本设置</h4><h5 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h5><p><a href="https://www.zotero.org/download/" target="_blank" rel="noopener">官网下载</a>：Zotero 和 Zotero Connector</p><h5 id="设置同步"><a href="#设置同步" class="headerlink" title="设置同步"></a>设置同步</h5><p>Zotero本身是自带同步功能的，但是自带的空间有限，可以使用webdav连接到其他网盘，以坚果云为例：<a href="http://help.jianguoyun.com/?p=3168" target="_blank" rel="noopener">如何在Zotero中设置webdav连接到坚果云？</a></p><h5 id="设置Zotfile"><a href="#设置Zotfile" class="headerlink" title="设置Zotfile"></a>设置Zotfile</h5><p>Zotfile是一款插件，配合Zotero可以更好地管理文献附件：<a href="http://zotfile.com/#how-to-install--set-up-zotfile" target="_blank" rel="noopener">下载和设置</a></p><h4 id="其它功能"><a href="#其它功能" class="headerlink" title="其它功能"></a>其它功能</h4><h5 id="导出文献列表（Word-Latex）"><a href="#导出文献列表（Word-Latex）" class="headerlink" title="导出文献列表（Word/Latex）"></a>导出文献列表（Word/Latex）</h5><h5 id="Papership（ipad-iphone端阅读）"><a href="#Papership（ipad-iphone端阅读）" class="headerlink" title="Papership（ipad/iphone端阅读）"></a>Papership（ipad/iphone端阅读）</h5>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>语义分割方法整理</title>
    <link href="http://yoursite.com/2019/09/23/Semantic-Segmentation/"/>
    <id>http://yoursite.com/2019/09/23/Semantic-Segmentation/</id>
    <published>2019-09-23T05:43:58.000Z</published>
    <updated>2019-09-23T08:01:14.874Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="Basis"><a href="#Basis" class="headerlink" title="Basis"></a>Basis</h4><ul><li>FCN<ul><li>[FCN] Fully Convolutional Networks for Semantic Segmentation [<a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="noopener">arXiv:1411.4038</a> | <a href="https://arxiv.org/abs/1605.06211" target="_blank" rel="noopener">arXiv:1605.06211</a>]</li></ul></li><li>DeepLab<ul><li>[DeepLab v1] Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs [<a href="https://arxiv.org/abs/1412.7062" target="_blank" rel="noopener">arXiv:1412.7062</a>]</li><li>[DeepLab v2] DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs [<a href="https://arxiv.org/abs/1606.00915" target="_blank" rel="noopener">arXiv:1606.00915</a>]</li><li>[DeepLab v3] Rethinking Atrous Convolution for Semantic Image Segmentation [<a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="noopener">arXiv:1706.05587</a>]</li><li>[DeepLab v3+] Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation [<a href="https://arxiv.org/abs/1802.02611" target="_blank" rel="noopener">arXiv:1802.02611</a>]<a id="more"></a></li></ul></li><li>Encoder-decoder Architecture<ul><li>[U-Net] U-Net: Convolutional Networks for Biomedical Image Segmentation </li><li>[SegNet] SegNet: A Deep Convolutional Encoder-Decoder Architecture for Scene Segmentation</li><li>[DeconvNet] Learning Deconvolution Network for Semantic Segmentation</li><li>[RefineNet] RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</li></ul></li></ul><h4 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h4><h5 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h5><ul><li>[CRFasRNN] Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</li><li>[MRF] Semantic Image Segmentation via Deep Parsing Network</li><li>[GRF] Fast, Exact and Multi-Scale Inference for Semantic Image Segmentation with Deep Gaussian CRFs</li></ul><h5 id="Atrous-Dilated-Convolution"><a href="#Atrous-Dilated-Convolution" class="headerlink" title="Atrous/Dilated Convolution"></a>Atrous/Dilated Convolution</h5><ul><li>[DUC-HDC] Understanding Convolution for Semantic Segmentation</li><li>[DRN] Dilated Residual Networks</li><li>Smoothed Dilated Convolutions for Improved Dense Prediction</li><li>Efficient Smoothing of Dilated Convolutions for Image Segmentation</li><li>[FastFCN] FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation</li></ul><h5 id="Context-Aggregation"><a href="#Context-Aggregation" class="headerlink" title="Context Aggregation"></a>Context Aggregation</h5><ul><li>Pooling<ul><li>[ParseNet] ParseNet: Looking Wider to See Better</li><li>[PSPNet] Pyramid Scene Parsing Network</li><li>[DenseASPP] DenseASPP for Semantic Segmentation in Street Scenes</li><li>[VortexPooling] Vortex Pooling: Improving Context Representation in Semantic Segmentation</li></ul></li><li>Large Kernel<ul><li>[GCN] Large Kernel Matters — Improve Semantic Segmentation by Global Convolutional Network</li><li>[ExFuse] ExFuse: Enhancing Feature Fusion for Semantic Segmentation</li></ul></li></ul><h5 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h5><ul><li>Channel Reweighting<ul><li>[DFN] Learning a Discriminative Feature Network for Semantic Segmentation</li><li>[EncNet] Context Encoding for Semantic Segmentation[</li><li>[SENet] Squeeze-and-Excitation Networks</li><li>Pyramid Attention Network for Semantic Segmentation</li></ul></li><li>Spatial Attention<ul><li>[OCNet] OCNet: Object Context Network for Scene Parsing</li><li>[DANet] Dual Attention Networks for Multimodal Reasoning and Matching</li><li>[PSANet] PSANet: Point-wise Spatial Attention Network for Scene Parsing</li><li>[CCNet] CCNet: Criss-Cross Attention for Semantic Segmentation</li></ul></li></ul><h5 id="Graph-Convolution"><a href="#Graph-Convolution" class="headerlink" title="Graph Convolution"></a>Graph Convolution</h5><ul><li>[GloRe] Graph-Based Global Reasoning Networks</li><li>Beyond Grids: Learning Graph Representations for Visual Recognition</li></ul><h4 id="Real-time-Method"><a href="#Real-time-Method" class="headerlink" title="Real-time Method"></a>Real-time Method</h4><h5 id="Convolution-Factorization"><a href="#Convolution-Factorization" class="headerlink" title="Convolution Factorization"></a>Convolution Factorization</h5><ul><li>[ENet] ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation</li><li>[ERFNet]  ERFNet: Efficient Residual Factorized ConvNet for Real-Time Semantic Segmentation</li><li>[ESPNet] ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation</li><li>[ESNet] ESNet: An Efficient Symmetric Network for Real-time Semantic Segmentation</li><li>[LEDNet] LEDNet: A Lightweight Encoder-Decoder Network for Real-Time Semantic Segmentation</li><li>[DABNet] DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation</li></ul><h5 id="Multi-branch"><a href="#Multi-branch" class="headerlink" title="Multi-branch"></a>Multi-branch</h5><ul><li>[ICNet] ICNet for Real-Time Semantic Segmentation on High-Resolution Images</li><li>[ContextNet] ContextNet: Exploring Context and Detail for Semantic Segmentation in Real-time</li><li>[BiSeNet] BiSeNet: Bilateral Segmentation Network for Real-Time Semantic Segmentation</li></ul><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><ul><li>语义分割论文整理 [<a href="https://zhangbin0917.github.io/2018/09/18/Semantic-Segmentation/" target="_blank" rel="noopener">blog</a>]</li><li>Survey on semantic segmentation using deep learning techniques [<a href="https://www.sciencedirect.com/science/article/pii/S092523121930181X" target="_blank" rel="noopener">paper</a>]</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Basis&quot;&gt;&lt;a href=&quot;#Basis&quot; class=&quot;headerlink&quot; title=&quot;Basis&quot;&gt;&lt;/a&gt;Basis&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;FCN&lt;ul&gt;
&lt;li&gt;[FCN] Fully Convolutional Networks for Semantic Segmentation [&lt;a href=&quot;https://arxiv.org/abs/1411.4038&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;arXiv:1411.4038&lt;/a&gt; | &lt;a href=&quot;https://arxiv.org/abs/1605.06211&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;arXiv:1605.06211&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DeepLab&lt;ul&gt;
&lt;li&gt;[DeepLab v1] Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs [&lt;a href=&quot;https://arxiv.org/abs/1412.7062&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;arXiv:1412.7062&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;[DeepLab v2] DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs [&lt;a href=&quot;https://arxiv.org/abs/1606.00915&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;arXiv:1606.00915&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;[DeepLab v3] Rethinking Atrous Convolution for Semantic Image Segmentation [&lt;a href=&quot;https://arxiv.org/abs/1706.05587&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;arXiv:1706.05587&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;[DeepLab v3+] Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation [&lt;a href=&quot;https://arxiv.org/abs/1802.02611&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;arXiv:1802.02611&lt;/a&gt;]&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="semantic segmentation" scheme="http://yoursite.com/tags/semantic-segmentation/"/>
    
  </entry>
  
  <entry>
    <title>道路场景语义分割</title>
    <link href="http://yoursite.com/2019/07/11/%E9%81%93%E8%B7%AF%E5%9C%BA%E6%99%AF%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://yoursite.com/2019/07/11/道路场景语义分割/</id>
    <published>2019-07-11T03:35:50.000Z</published>
    <updated>2019-09-23T07:35:26.572Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><ul><li><a href="http://apolloscape.auto/scene.html" target="_blank" rel="noopener">Apolloscape Scene Parsing</a></li><li><a href="https://bair.berkeley.edu/blog/2018/05/30/bdd/" target="_blank" rel="noopener">BDD100k</a></li><li><a href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/" target="_blank" rel="noopener">CamVid</a></li><li><a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener">Cityscapes</a></li><li><a href="http://www.6d-vision.com/scene-labeling" target="_blank" rel="noopener">Daimler Urban Segmentation</a></li><li><a href="http://www.cvlibs.net/datasets/kitti/eval_semantics.php" target="_blank" rel="noopener">Kitti</a></li><li><a href="https://www.mapillary.com/dataset/" target="_blank" rel="noopener">Mapillary Vistas</a></li></ul><h4 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h4><table><thead><tr><th>Method</th><th>Cityscapes(%)</th><th>CamVid(%)</th><th>Publication</th></tr></thead><tbody><tr><td>FCN-8s</td><td>65.3</td><td></td><td>CVPR2015</td></tr><tr><td>SegNet</td><td></td><td>50.2</td><td>arXiv15</td></tr><tr><td>DeepLab v2</td><td>70.4</td><td></td><td>PAMI2018</td></tr><tr><td>G-FRNet</td><td></td><td>68.0</td><td>CVPR2017</td></tr><tr><td>FRRN B</td><td>71.8</td><td></td><td>CVPR2017</td></tr><tr><td>RefineNet</td><td>73.6</td><td></td><td>CVPR2017</td></tr><tr><td>GCN</td><td>76.9</td><td></td><td>CVPR2017</td></tr><tr><td>TKCN</td><td>79.5</td><td></td><td>ICME2019</td></tr><tr><td>DUC-HDC</td><td>80.1</td><td></td><td>WACV2018</td></tr><tr><td>PSANet</td><td>80.1</td><td></td><td>ECCV2018</td></tr><tr><td>PSPNet</td><td>80.2</td><td></td><td>CVPR2017</td></tr><tr><td>DDSC</td><td></td><td>70.9</td><td>CVPR2018</td></tr><tr><td>DFN</td><td>80.3</td><td></td><td>CVPR2018</td></tr><tr><td>DenseASPP</td><td>80.6</td><td></td><td>CVPR2018</td></tr><tr><td>LDN</td><td>80.6</td><td>78.1</td><td>arXiv19</td></tr><tr><td>GloRe</td><td>80.9</td><td></td><td>CVPR2019</td></tr><tr><td>OCNet</td><td>81.2</td><td></td><td>arXiv18</td></tr><tr><td>DeepLab v3</td><td>81.3</td><td></td><td>arXiv17</td></tr><tr><td>CCNet</td><td>81.4</td><td></td><td>arXiv18</td></tr><tr><td>DAN</td><td>81.5</td><td></td><td>CVPR2019</td></tr><tr><td>HRNetV2</td><td>81.6</td><td></td><td>arXiv19</td></tr><tr><td>CaseNet</td><td>81.9</td><td></td><td>arXiv19</td></tr><tr><td>DeepLab v3+</td><td>82.1</td><td></td><td>ECCV2018</td></tr><tr><td>GFF</td><td>82.3</td><td></td><td>arXiv19</td></tr><tr><td>DPC</td><td>82.7</td><td></td><td>NIPS2018</td></tr><tr><td>GSCNN</td><td>82.8</td><td></td><td>ICCV2019</td></tr></tbody></table><h4 id="Real-time-Method"><a href="#Real-time-Method" class="headerlink" title="Real-time Method"></a>Real-time Method</h4><table><thead><tr><th>Method</th><th>WxH</th><th>mIOU(%)</th><th>FPS</th><th>GFLOPs</th><th>Param(M)</th></tr></thead><tbody><tr><td>ENet</td><td>1920x1080</td><td>58.3</td><td>21.6</td><td>3.83</td><td>0.37</td></tr><tr><td>SQ</td><td>2048x1024</td><td>59.8</td><td>-</td><td>-</td><td>-</td></tr><tr><td>TwoColumn</td><td>1024x512</td><td>72.9</td><td>14.7</td><td>-</td><td>-</td></tr><tr><td>CGNet</td><td>2048x1024</td><td>64.8</td><td>17.6</td><td>6</td><td>0.5</td></tr><tr><td>ESPNet</td><td>-</td><td>60.3</td><td>4</td><td>-</td><td>0.4</td></tr><tr><td>ERFNet</td><td>-</td><td>68</td><td>-</td><td>-</td><td>-</td></tr><tr><td>ICNet</td><td>2048x1024</td><td>69.5</td><td>30.3</td><td>-</td><td>-</td></tr><tr><td>BiSeNet</td><td>1536x768</td><td>68.4</td><td>105.8</td><td>2.9</td><td>5.8</td></tr><tr><td></td><td>1536x768</td><td>74.7</td><td>65.5</td><td>10.8</td><td>49</td></tr><tr><td>ESNet</td><td>-</td><td>70.7</td><td>63</td><td>-</td><td>1.66</td></tr><tr><td>DFANet</td><td>1024x1024</td><td>71.3</td><td>100</td><td>3.4</td><td>7.8</td></tr><tr><td>LEDNet</td><td>1024x512</td><td>70.1</td><td>71</td><td>-</td><td>0.94</td></tr><tr><td>DABNet</td><td>1024x512</td><td>70.1</td><td>104.2</td><td>-</td><td>0.76</td></tr><tr><td>SqueezeNAS</td><td>1024x512</td><td>72.5</td><td>-</td><td>-</td><td>1.9</td></tr></tbody></table><p>*上表为文献中各方法在Cityscapes上的性能</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="semantic segmentation" scheme="http://yoursite.com/tags/semantic-segmentation/"/>
    
  </entry>
  
  <entry>
    <title>一个测试</title>
    <link href="http://yoursite.com/2018/05/11/%E4%B8%80%E4%B8%AA%E6%B5%8B%E8%AF%95/"/>
    <id>http://yoursite.com/2018/05/11/一个测试/</id>
    <published>2018-05-11T11:20:15.000Z</published>
    <updated>2019-02-05T07:46:59.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>ヾ(๑╹◡╹)ﾉ”  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
      <category term="胡言" scheme="http://yoursite.com/categories/%E8%83%A1%E8%A8%80/"/>
    
    
  </entry>
  
</feed>
