<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习笔记]]></title>
    <url>%2F2020%2F02%2F25%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1 引言 1.1 机器学习定义第一个定义——Arthur Samuel对机器学习的定义： 机器学习是这样的领域，它赋予计算机学习的能力，这种学习学习能力不是通过显著式编程获得的。 显著式编程：比如发一系列指令（左转-开门-右转……）让机器人到教室门外的咖啡机前冲咖啡，其劣势是需要把机器人所处的环境调查得一清二楚， 非显著式编程：让计算机自己总结规律的编程方法。比如规定行为（如左转、后退等）和收益函数（如摔倒时收益函数为负值），让计算机自己去找最大化收益函数的行为模式。 第二个定义——Tom Mitshell于1998年在他的书《Machine Learning》中的定义 一个计算机程序被称为可以学习，是指它能够针对某个任务T和某个性能指标P，从经验E中学习。这种学习的特点是，它在T上的被P所衡量的性能，会随着经验E的增加而提高。 任务（Task, T） 经验（Experience, E） 性能指标（Performance Measure, P） 1.2 机器学习任务的分类按照任务是否需要和环境交互获得经验分为监督学习和强化学习两类。比如在以下四个任务中，2和3属于监督学习，所有经验E都是人工采集（训练数据+标签）并输入计算机；1和4属于强化学习，经验E是由计算机与环境互动获得的。不过这样的划分并不绝对，比如在ALPHAGO中，首先通过监督学习（棋局）获得初始围棋程序，再通过强化学习提升棋力。 教计算机下棋 垃圾邮件识别 人脸识别 无人驾驶 对于监督学习可以进一步分类。 按照训练数据是否存在标签分为 传统监督学习 支持向量机 人工神经网络 深度神经网络 无监督学习 聚类 EM算法 主成分分析 半监督学习 按照标签是连续还是离散分为 分类 回归 1.3 机器学习算法的过程特征提取、特征选择 → 不同的算法对特征空间做不同的划分 → 不同的结果 1.4 没有免费午餐定理1995年，D.H.Wolpert等人提出没有免费午餐定理（No Free Lunch Theorem）： 任何一个预测函数，如果在一些训练样本上表现好，那么必然在另一些训练样本上表现不好，如果不对数据在特征空间的先验分布有一定假设，那么表现好与表现不好的情况一样多。 即如果不对特征空间的先验分布有假设，那么所有算法的表现都是一样的。一方面，机器学习的本质是通过有限的已知数据在复杂的高位特征空间中预测未知的样本，然而并不知道未知样本在哪里，性质到底如何，所以再好的算法也有犯错的风险；另一方面，没有放之四海而皆准的最好算法，因为评价算法的好坏涉及到对特征空间先验分布的假设，然而没有人知道先验分布的真实样子。 在设计机器学习算法时的常用假设： 在特征空间上距离接近的样本，他们属于同一个类别的概率会更高。 2 支持向量机2.1 线性可分定义]]></content>
      <categories>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Photoshop精简操作]]></title>
    <url>%2F2020%2F02%2F20%2FPhotoshop%E7%B2%BE%E7%AE%80%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[1 PS设计基础 1.1 工作区和工作流程工作区：上方为菜单栏，左侧为工具栏，右侧为功能面板工作流程：同一个任务往往有多种操作方式 例：图像亮度调整 1. 图像菜单 &gt;&gt; 调整 &gt;&gt; 亮度/对比度2. 图像菜单 &gt;&gt; 调整 &gt;&gt; 亮度/色阶3. 获取亮度选区 + 混合模式 1.2 色彩基础和吸管工具组色彩基础 RGB色轮：光的三原色 伊顿色轮：美术三原色 吸管工具组 吸管工具：取样点的选择。默认单个像素，也可以取3x3平均，31x31平均等 颜色取样器工具：配合信息面板获得跟踪颜色取样值 信息面板 删除取样点 窗口菜单 &gt;&gt; 信息面板 1. 按住Option点击取样点2. 点击选项面板”清楚全部“按钮 标尺工具：配合信息面板获得两点间的标尺线段信息 计数工具：在适当位置进行标记，有计数编组等功能 1.3 拾色器和色彩空间拾色器：可通过点击工具栏的前景色进入。常见的四种色彩模型如下 HSB：色相/饱和度/亮度 Lab：明度/a分量/b分量，a从品红到绿色，b从蓝色到黄色 RGB：红/绿/蓝 CMYK：青/洋红/黄/黑（定调色Key），即三原色的补色+黑色 HSB取色步骤 1. 选择色相值，对应色轮上的度数2. 选择饱和度，可以理解为颜色中有多少白色3. 选择亮度，可以理解为颜色中有多少黑色 通过颜色库取色，通常用于印刷场合。 冷知识：世界上最丑的颜色 Pantone 448 C（Pantone是最大的色彩厂商），一种深棕色 色彩空间 = 色彩模型 + 色域。如果把色彩模型理解为用数字来描述颜色，色彩空间则需要和一个具体的设备关联起来（如肉眼、电脑屏幕等） 1.4 数字图像处理：尺寸更改图像标签页显示的信息有图像的缩放率（图像窗口左下角可手动输入），色彩模式和通道数（对应图像菜单 &gt;&gt; 模式）。图像窗口左下角还可以指定的常用信息有 文档大小：图像文档在PS内部以无损方式存储所占用的体积 文档尺寸：图像文档的宽和高在某个度量单位下的数值 文档配置文件：对应于编辑菜单 &gt;&gt; 指定配置文件/转换为配置文件 有必要了解虚拟单位、实际单位和分辨率的概念 虚拟单位：像素、点、百分比 实际单位：英寸、厘米、毫米 分辨率：PPI（每英寸像素数）、DPI（每英寸点数） 显示打印尺寸 为了该命令能发挥正常功能，需要先更改预设分辨率。1. 首选项面板 &gt;&gt; 单位与标尺：填写正确的与当前设备屏幕属性一致的屏幕分辨率数值。2. 视图菜单 &gt;&gt; 打印尺寸：根据预设参数，在屏幕上显示图像文档的实际尺寸，即物理尺寸。 其中屏幕分辨率的计算：比如屏幕宽度的虚拟尺寸为1440像素，实际尺寸为15英寸，那么屏幕分辨率可估算为1440/15=96像素/英寸（之所以说是估算因为15英寸指的是对角线长） 尺寸调整相关 1. 图像菜单 &gt;&gt; 图像大小：设置图像的宽、高和分辨率。注意等比例缩放和重新采样选项。2. 图像菜单 &gt;&gt; 画布大小：设置画布的宽和高。推荐勾选相对选项。3. 图像菜单/工具栏 &gt;&gt; 裁剪：同时裁剪图像和画布大小。注意不要勾选删除裁剪的像素选项。 1.5 数字图像处理：文件格式 体积 视觉损失 透明 特性 JPG/JPEG 较小 有损 不支持 常用于照片、绘画 PNG 较大 无损 索引透明或Alpha透明 常用于资源类图像 GIF 中等较大 索引颜色 索引透明 常用于动画、图标 JPG格式不支持透明度，透明区域将被自动填充为背景色. PNG-8格式支持索引透明，每个像素只能是全透明（100%透明）或者不透明。 PNG-24格式支持Alpha透明，每个像素都拥有256级别的透明度。 GIF格式支持索引透明；拥有至多256种颜色（索引颜色）；支持动画。 Tip 使用文件菜单 &gt;&gt; 导出 &gt;&gt; 存储为Web所有格式（旧版）…便于观察最后结果和相互对比 2 绘画、修饰、选择工具和选取初步2.1 画笔工具组2.2 历史记录画笔2.3 橡皮擦和油漆桶工具组2.4 仿制图章和修饰工具组2.5 选区初步]]></content>
      <categories>
        <category>指南</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Zotero简明使用指南]]></title>
    <url>%2F2020%2F01%2F08%2FZotero%E7%AE%80%E6%98%8E%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[一款免费易用的文献管理工具 下载与基本设置 下载官网下载Zotero和Zotero Connector。前者是管理文献的本体；后者是用于抓取条目和相关附件的浏览器插件。 设置同步Zotero本身自带同步功能，但是自带空间有限，故可以使用webdav连接到其他网盘，以坚果云为例：如何在Zotero中设置webdav连接到坚果云？ 设置ZotfileZotfile是一款插件，配合Zotero使用可以更好地管理（批量命名和移除等）文献附件：下载和设置。 其它功能 导出参考文献（Word/Latex）若不使用插件，❶直接拖拽条目至文本编辑器/使用快捷键即可实现单条目的快速复制；❷在Zotero中选取所需条目，右键选择由所选条目创建引文目录即可实现多条目的快速复制。若使用插件，以Word为例，在成功安装插件的前提下Word菜单栏中会出现Zotero选项卡，可方便地添加引用和参考文献。 Papership（ipad/iphone端）Zotero只有PC端应用，配合Papership使用可以弥补该不足。用Zotero账户登录Papership应用，并设置Zotero File Hosting（与步骤1.2设置同步类似）就可以在平板和手机上同步阅读文献了。]]></content>
      <categories>
        <category>指南</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[语义分割方法整理]]></title>
    <url>%2F2019%2F09%2F23%2FSemantic-Segmentation%2F</url>
    <content type="text"><![CDATA[持续更新 Basis FCN [FCN] Fully Convolutional Networks for Semantic Segmentation DeepLab [DeepLab v1] Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs [DeepLab v2] DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs [DeepLab v3] Rethinking Atrous Convolution for Semantic Image Segmentation [DeepLab v3+] Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation Encoder-decoder Architecture [U-Net] U-Net: Convolutional Networks for Biomedical Image Segmentation [SegNet] SegNet: A Deep Convolutional Encoder-Decoder Architecture for Scene Segmentation [DeconvNet] Learning Deconvolution Network for Semantic Segmentation [RefineNet] RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation MethodCRF [CRFasRNN] Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials [MRF] Semantic Image Segmentation via Deep Parsing Network [GRF] Fast, Exact and Multi-Scale Inference for Semantic Image Segmentation with Deep Gaussian CRFs Atrous/Dilated Convolution [DUC-HDC] Understanding Convolution for Semantic Segmentation [DRN] Dilated Residual Networks Smoothed Dilated Convolutions for Improved Dense Prediction Efficient Smoothing of Dilated Convolutions for Image Segmentation [FastFCN] FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation Context Aggregation Pooling [ParseNet] ParseNet: Looking Wider to See Better [PSPNet] Pyramid Scene Parsing Network [DenseASPP] DenseASPP for Semantic Segmentation in Street Scenes [VortexPooling] Vortex Pooling: Improving Context Representation in Semantic Segmentation Large Kernel [GCN] Large Kernel Matters — Improve Semantic Segmentation by Global Convolutional Network [ExFuse] ExFuse: Enhancing Feature Fusion for Semantic Segmentation Attention Mechanism Channel Reweighting [DFN] Learning a Discriminative Feature Network for Semantic Segmentation [EncNet] Context Encoding for Semantic Segmentation[ [SENet] Squeeze-and-Excitation Networks Pyramid Attention Network for Semantic Segmentation Spatial Attention [OCNet] OCNet: Object Context Network for Scene Parsing [DANet] Dual Attention Networks for Multimodal Reasoning and Matching [PSANet] PSANet: Point-wise Spatial Attention Network for Scene Parsing [CCNet] CCNet: Criss-Cross Attention for Semantic Segmentation Graph Convolution [GloRe] Graph-Based Global Reasoning Networks Beyond Grids: Learning Graph Representations for Visual Recognition Real-time MethodConvolution Factorization [ENet] ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation [ERFNet] ERFNet: Efficient Residual Factorized ConvNet for Real-Time Semantic Segmentation [ESPNet] ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation [ESNet] ESNet: An Efficient Symmetric Network for Real-time Semantic Segmentation [LEDNet] LEDNet: A Lightweight Encoder-Decoder Network for Real-Time Semantic Segmentation [DABNet] DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation Multi-branch [ICNet] ICNet for Real-Time Semantic Segmentation on High-Resolution Images [ContextNet] ContextNet: Exploring Context and Detail for Semantic Segmentation in Real-time [BiSeNet] BiSeNet: Bilateral Segmentation Network for Real-Time Semantic Segmentation Reference 语义分割论文整理 [blog] Survey on semantic segmentation using deep learning techniques [paper]]]></content>
      <categories>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[道路场景语义分割]]></title>
    <url>%2F2019%2F07%2F11%2F%E9%81%93%E8%B7%AF%E5%9C%BA%E6%99%AF%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%2F</url>
    <content type="text"><![CDATA[持续更新 Datasets Apolloscape Scene Parsing BDD100k CamVid Cityscapes Daimler Urban Segmentation Kitti Mapillary Vistas Method Method Cityscapes(%) CamVid(%) Publication FCN-8s 65.3 CVPR2015 SegNet 50.2 arXiv15 DeepLab v2 70.4 PAMI2018 G-FRNet 68.0 CVPR2017 FRRN B 71.8 CVPR2017 RefineNet 73.6 CVPR2017 GCN 76.9 CVPR2017 TKCN 79.5 ICME2019 DUC-HDC 80.1 WACV2018 PSANet 80.1 ECCV2018 PSPNet 80.2 CVPR2017 DDSC 70.9 CVPR2018 DFN 80.3 CVPR2018 DenseASPP 80.6 CVPR2018 LDN 80.6 78.1 arXiv19 GloRe 80.9 CVPR2019 OCNet 81.2 arXiv18 DeepLab v3 81.3 arXiv17 CCNet 81.4 arXiv18 DAN 81.5 CVPR2019 HRNetV2 81.6 arXiv19 CaseNet 81.9 arXiv19 DeepLab v3+ 82.1 ECCV2018 GFF 82.3 arXiv19 DPC 82.7 NIPS2018 GSCNN 82.8 ICCV2019 Real-time Method Method WxH mIOU(%) FPS GFLOPs Param(M) ENet 1920x1080 58.3 21.6 3.83 0.37 SQ 2048x1024 59.8 - - - TwoColumn 1024x512 72.9 14.7 - - CGNet 2048x1024 64.8 17.6 6 0.5 ESPNet - 60.3 4 - 0.4 ERFNet - 68 - - - ICNet 2048x1024 69.5 30.3 - - BiSeNet 1536x768 68.4 105.8 2.9 5.8 1536x768 74.7 65.5 10.8 49 ESNet - 70.7 63 - 1.66 DFANet 1024x1024 71.3 100 3.4 7.8 LEDNet 1024x512 70.1 71 - 0.94 DABNet 1024x512 70.1 104.2 - 0.76 SqueezeNAS 1024x512 72.5 - - 1.9 *上表为文献中各方法在Cityscapes上的性能]]></content>
      <categories>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一个测试]]></title>
    <url>%2F2018%2F05%2F11%2F%E4%B8%80%E4%B8%AA%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[ヾ(๑╹◡╹)ﾉ”]]></content>
      <categories>
        <category>胡言</category>
      </categories>
  </entry>
</search>
