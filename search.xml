<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习笔记]]></title>
    <url>%2F2020%2F02%2F25%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1 引言1.1 机器学习定义第一个定义——Arthur Samuel对机器学习的定义： 机器学习是这样的领域，它赋予计算机学习的能力，这种学习能力不是通过显著式编程获得的。 显著式编程：比如发一系列指令（左转-开门-右转……）让机器人到教室门外的咖啡机前冲咖啡，其劣势是需要把机器人所处的环境调查得一清二楚， 非显著式编程：让计算机自己总结规律的编程方法。比如规定行为（如左转、后退等）和收益函数（如摔倒时收益函数为负值），让计算机自己去找最大化收益函数的行为模式。 第二个定义——Tom Mitshell于1998年在他的书《Machine Learning》中的定义 一个计算机程序被称为可以学习，是指它能够针对某个任务T和某个性能指标P，从经验E中学习。这种学习的特点是，它在T上的被P所衡量的性能，会随着经验E的增加而提高。 任务（Task, T） 经验（Experience, E） 性能指标（Performance Measure, P） 1.2 机器学习任务的分类按照任务是否需要和环境交互获得经验分为监督学习和强化学习两类。比如在以下四个任务中，2和3属于监督学习，所有经验E都是人工采集（训练数据+标签）并输入计算机；1和4属于强化学习，经验E是由计算机与环境互动获得的。不过这样的划分并不绝对，比如在ALPHAGO中，首先通过监督学习（棋局）获得初始围棋程序，再通过强化学习提升棋力。 教计算机下棋 垃圾邮件识别 人脸识别 无人驾驶 对于监督学习可以进一步分类。 按照训练数据是否存在标签分为 传统监督学习 支持向量机 人工神经网络 深度神经网络 无监督学习 聚类 EM算法 主成分分析 半监督学习 按照标签是连续还是离散分为 分类 回归 1.3 机器学习算法的过程特征提取、特征选择 → 不同的算法对特征空间做不同的划分 → 不同的结果 1.4 没有免费午餐定理1995年，D.H.Wolpert等人提出没有免费午餐定理（No Free Lunch Theorem）： 任何一个预测函数，如果在一些训练样本上表现好，那么必然在另一些训练样本上表现不好，如果不对数据在特征空间的先验分布有一定假设，那么表现好与表现不好的情况一样多。 即如果不对特征空间的先验分布有假设，那么所有算法的表现都是一样的。再好的算法也有犯错的风险，因为机器学习的本质是通过有限的已知数据在复杂的高维特征空间中预测未知的样本，然而没有人知道未知样本在哪里，性质到底如何；也没有放之四海而皆准的最好算法，因为评价算法的好坏涉及到对特征空间先验分布的假设，然而没有人知道先验分布的真实样子。 在设计机器学习算法时的常用假设： 在特征空间上距离接近的样本，他们属于同一个类别的概率会更高。 ## 2 支持向量机 2.1 问题描述首先，明确线性可分和非线性可分的基础概念。 直观定义： 对于二维特征空间，存在一条直线将训练样本分开为线性可分，反之为非线性可分； 对于高维特征空间，存在一个超平面将训练样本分开为线性可分，反之为非线性可分。 数学定义： 假设我们有$N$个训练样本和它们的标签：$$\begin{aligned} &amp;\left{\left(X_{1}, y_{1}\right),\left(X_{2}, y_{2}\right), \ldots,\left(X_{N}, y_{N}\right)\right}\ &amp;X_{i}=\left[x_{i 1}, x_{i 2}\right]^{T}\ &amp;y_{i}={+1,-1} \end{aligned}$$线性可分是指存在 $(\omega,b)$ 使得对 $i=1\sim N$ 有$$y_{i}\left(\omega^{T} X_{i}+b\right)&gt;0$$ 1995年，Vladimir Vapnik提出支持向量机寻找的最优分类直线应满足以下3个条件。 该直线分开了两类 该直线最大化间隔（margin） 该直线处于间隔的中间，到所有支持向量的距离相等 此时我们把样本点中与分离超平面距离最近的数据点称为支持向量。在决定最佳超平面时只有支持向量起作用，而其他数据点并不起作用。如果移动非支持向量，甚至删除非支持向量都不会对最优超平面产生任何影响。 2.2 线性可分-硬间隔假定训练样本是线性可分的，该优化问题可以写成如下形式：$$\begin{eqnarray}\text {Minimize: }&amp;&amp; \frac{1}{2}|\omega|^{2} \tag{2.2.1}\\text{s.t.: }&amp;&amp; {y}{i}\left(\omega^{T} x{i}+b\right) \geq 1,(i=1 \sim N) \tag{2.2.2}\end{eqnarray}$$其中待求的是 $\omega$ 和 $b$ ，该形式的推导过程如下。 [事实1] $(\omega,b)$ 表示的超平面和 $(a\omega,ab)$ 表示的超平面是同一个平面。所以我们可以用参数 $a$ 来缩放 $(\omega,b)$，使它满足下式。$$\begin{aligned}&amp;\left|\omega^{T} x_{0}+b\right|=1 \quad \text{on support vector}\ x_{0}\&amp;\left|\omega^{T} x_{0}+b\right|&gt;1 \quad \text{on non-support vectors}\end{aligned}$$限制条件 (2.2.2) 中 $y_{i}$ 可以协调超平面的左右，使得对于非支持向量分布于超平面的两侧。 [事实2] 支持向量到超平面的距离公式众所周知。结合事实1可得到下式，所以要最大化支持向量到超平面的距离就等价于最小化 $|\omega|$。$$d=\frac{\left|\omega^{T} x_{0}+b\right|}{|\omega|}=\frac{1}{|\omega|}$$ 最后目标函数的形式如 (2.2.1) 所示，主要是为了求导的方便。 2.3 非线性可分-软间隔在线性不可分情况下，不存在 $(\omega,b)$ 满足如 (2.2.2) 的限制条件，所以需要适当放松限制条件，引入松弛变量 $\delta_{i}$ ，同时也要限制 $\delta_{i}$ 的范围避免其无限大。改造后的优化问题如下所示：$$\begin{eqnarray}\text {Minimize: }&amp;&amp; \frac{1}{2}|\omega|^{2}+C \sum_{i=1}^{N} \delta_{i}^{2}\\text{s.t.: }&amp;&amp;(1)\ \delta_{i} \geq 0,(i=1 \sim N)\&amp;&amp;(2)\ y_{i}\left(\omega^{T} X_{i}+b\right) \geq 1-\delta_{i},(i=1 \sim N)\end{eqnarray}$$其中 $(\omega,b,\delta_{i})$ 为待求项，比例因子 $C$ 作为超参数 (Hyper Parameter) 需要人为设定，起到了平衡两项的作用。 2.4 非线性可分-核技巧软间隔的方式作用有限，对于非线性可分数据集有时需要曲面，所以只能扩大可选函数的范围使其超越线性。基本思路是将训练样本的特征空间从低维映射到高维，再用线性超平面对数据进行分类。以异或问题为例： 我们不妨先假设这个映射函数为 $\phi(x)$ ，那么优化问题将变为如下形式：$$\begin{eqnarray}\text {Minimize: }&amp;&amp; \frac{1}{2}|\omega|^{2}+C \sum_{i=1}^{N} \delta_{i}^{2}\\text{s.t.: }&amp;&amp;(1)\ \delta_{i} \geq 0,(i=1 \sim N)\&amp;&amp;(2)\ y_{i}\left[\omega^{T} \varphi(X_{i})+b\right] \geq 1-\delta_{i},(i=1 \sim N)\end{eqnarray}$$求解上述优化问题的对偶问题涉及到计算 $\varphi\left(X_{1}\right)^{T} \varphi\left(X_{2}\right)$。由于特征空间维数可能很高，甚至可能是无穷维，因此直接计算 $\varphi\left(X_{1}\right)^{T}\varphi\left(X_{2}\right)$ 通常是困难的，为了避开这个障碍，我们引入核函数 $K$。后续章节将说明我们不需要显式地定义映射 $\varphi $ 是什么，而只需事先定义核函数 $K$ ，就可以利用解线性问题的方法求解非线性问题的支持向量机。本节首先对核函数 $K$ 有个初步的了解。 核函数的定义：$K\left(X_{1}, X_{2}\right)=\varphi\left(X_{1}\right)^{T} \varphi\left(X_{2}\right)$ 核函数的充要条件：①交换性；②半正定性 。（Mercer定理） 核函数 $K$ 和映射函数 $\phi $ 一一对应。 常用核函数： 2.5 原问题和对偶问题 原问题（Prime Problem） 其中自变量 $\omega$ 为多维向量，$f(\omega)$为目标函数，$g_{i}(\omega)$ 和 $h_{i}(\omega)$为限制条件。 $$\begin{aligned}\text {Minimize: }&amp; f(\omega) \\text{s.t.: }&amp; g_{i}(\omega) \leq 0 \quad i=1 \sim K \&amp;h_{i}(\omega)=0 \quad i=1 \sim m\end{aligned}$$ 对偶问题（Dual Problem） 首先定义函数$$\begin{aligned}L(\omega, \alpha, \beta) &amp;=f(\omega)+\sum_{i=1}^{K} \alpha_{i} g_{i}(\omega)+\sum_{i=1}^{M} \beta_{i} h_{i}(\omega) \&amp;=f(\omega)+\alpha^{T} g(\omega)+\beta^{T} h(\omega)\end{aligned}$$在此基础上定义对偶问题如下,其中 $\theta(\alpha, \beta)$ 表示在遍历所有的 $\omega$ 后取 $L(\omega, \alpha, \beta)$ 的最小值$$\begin{aligned}\text{Maxmize: }&amp; \theta(\alpha, \beta)=\inf_{\omega} \ L(\omega, \alpha, \beta) \\text{s.t.: }&amp; \alpha_{i} \geq 0, i=1 \sim K\end{aligned}$$ 原问题与对偶问题的关系 [定理1] 弱对偶性：如果 $\omega^$ 是原问题的解，$\alpha^$ 和 $\beta^$ 是对偶问题的解，那么$$f\left(\omega^{}\right) \geqslant \theta\left(\alpha^{}, \beta^{}\right)$$证明：$$\begin{aligned}\theta\left(\alpha^{}, \beta^{}\right) &amp;=\inf L\left(\omega, \alpha^{}, \beta^{}\right) \&amp; \leq L\left(w^{}, \alpha^{}, \beta^{}\right) \&amp;=f\left(\omega^{}\right)+\alpha^{* T} g\left(\omega^{}\right)+\beta^{ T} h\left(\omega^{}\right) \&amp; \leq f\left(\omega^{}\right)\end{aligned}$$ [定理2] 强对偶性：如果 $g(\omega)=A\omega+b$，$h(\omega)=C\omega+d$，$f(\omega)$ 为凸函数，那么$$f\left(\omega^{}\right)=\theta\left(\alpha^{}, \beta^{*}\right)$$证明略，见附录1。 [定义1] Slater条件：即强对偶性成立的条件。 [定义2] KKT条件：对所有 $i=1\sim K$ 要么 $\alpha_{i}^{}=0$， 要么 $g(\omega^{})=0$ 推导：由定理1证明部分的第3行到第4行易知，要取等号必须满足KKT条件。 注释：KKT是三人名字的首字母。 2.6 SVM转化为对偶问题2.7 算法总体流程接着2.6节，总结支持向量机训练和测试的流程。 训练过程 （1）输入训练数据$$\left{\left(X_{i}, y_{i}\right)\right},\text{where }y_{i}={+1,-1}$$（2）用SMO算法求解如下优化问题，解出 $\alpha_{i}$$$\begin{eqnarray}\text{Maxmize: }&amp;&amp; \theta(\alpha, \beta)=\sum_{i=1}^{N} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} y_{i} y_{j} \alpha_{i} \alpha_{j} \varphi\left(X_{i}\right)^{\mathrm{T}} \varphi\left(X_{j}\right) \tag{2.7.1}\\text{s.t.: }&amp;&amp; (1)\ 0\leq \alpha_{i} \leq C, \ i=1 \sim N \&amp;&amp;(2)\ \sum_{i=1}^{N} \alpha_{i} y_{i}=0, \ i=1 \sim N\end{eqnarray}$$（3）找一个 $\alpha_{i}\neq 0$ 且 $\alpha_{i}\neq C$ ，利用下式求 $b$$$b=\frac{1-\sum_{j=1}^{N} \alpha_{j} y_{i} y_{j} K\left(X_{j}, X_{i}\right)}{y_{i}} \tag{2.7.2}$$ 测试过程 考察测试数据 $X$，预测其类别 $y$ $$\begin{aligned}&amp;\text{if }\sum_{i=1}^{N} \alpha_{i} y_{i} K\left(X_{i}, X\right)+b \geq 0, \quad \text{then } y=+1\&amp;\text{if }\sum_{i=1}^{N} \alpha_{i} y_{i} K\left(X_{i}, X\right)+b&lt;0, \quad \text{then } y=-1\end{aligned}$$ [推导] 在通过解凸优化问题得到 $\alpha_{i}$ 后，求偏移项 $b$ 的过程如下$$\omega=\sum_{j=1}^{N} \alpha_{j} y_{j} \varphi\left(X_{i}\right)$$ $$\begin{aligned}\omega^{T} \varphi\left(x_{i}\right) &amp;=\sum_{j=1}^{N} \alpha_{j} y_{j} \varphi\left(X_{j}\right)^{T} \varphi\left(X_{i}\right) \&amp;=\sum_{j=1}^{N} \alpha_{j} y_{j} K\left(X_{j}, X_{i}\right)\end{aligned}$$ 根据KKT条件有$$\begin{aligned}&amp;\alpha_{i}\left[1+\delta_{i}-y_{i} \omega^{T} \varphi\left(X_{i}\right)-y_{i} b\right]=0 \&amp;\beta_{i} \delta_{i}=0 \Rightarrow \left(c-\alpha_{i}\right) \delta_{i}=0\end{aligned}$$如果对某个 $i$，$\alpha_{i}\neq 0$ 且 $\alpha_{i}\neq C$ 那么必有$$\delta_{i}=0 \1+\delta_{i}-y_{i} \omega^{T} \varphi\left(X_{i}\right)-y_{i} b=0$$从而得到式 (2.7.2)$$b=\frac{1-\sum_{j=1}^{N} \alpha_{j} y_{i} y_{j} K\left(X_{j}, X_{i}\right)}{y_{i}}$$ [注释] SMO算法：SMO 的基本思路是先固定 $\alpha_{i}$ 之外的所有参数，然后求 $\alpha_{i}$ 的极值。由于存在约束 $\sum_{i=1}^{N} \alpha_{i} y_{i}=0$，若固定 $\alpha_{i}$ 之外的其他变量，则 $\alpha_{i}$ 可由其他变量导出。于是， SMO 每次选择两个变量 $\alpha_{i}$ 和 $\alpha_{j}$ ，并固定其他参数。这样，在参数初始化后， SMO 不断执行如下两个步骤直至收敛： 选取一对需更新的变量 $\alpha_{i}$ 和 $\alpha_{j}$； 固定 $\alpha_{i}$ 和 $\alpha_{j}$ 以外的参数，求解式 (2.7.1) 获得更新后的 $\alpha_{i}$ 和 $\alpha_{j}$。 [概念] 二次规划问题：二次规划 (Quadratic Programming，简称 QP)是一类典型的优化问题，包括凸二次优化和非凸二次优化。在此类问题中，目标函数是变量的二次函数，而约束条件是变量的线性不等式。假定变量个数为 $d$， 约束条件的个数为 $m$，则标准的二次规划问题形如$$\begin{aligned}&amp;\min _{\boldsymbol{x}} \frac{1}{2} \boldsymbol{x}^{\mathrm{T}} \mathbf{Q} \boldsymbol{x}+\boldsymbol{c}^{\mathrm{T}} \boldsymbol{x}\&amp;\text { s.t. } \quad \mathbf{A} \boldsymbol{x} \leqslant \boldsymbol{b}\end{aligned}$$若 $\mathbf{Q}$ 为半正定矩阵，则目标函数是凸函数，相应的二次规划是凸二次优化问题，此时该问题要么无解要么有全局最小值；若 $\mathbf{Q}$ 为正定矩阵，则该问题有唯一的全局最小值；若 $\mathbf{Q}$ 为非正定矩阵，则上式是有多个平稳点和局部极小点的 NP 难问题。 2.8 兵王问题2.9 性能度量首先，介绍混淆矩阵如下： 实际\预测 正样本 负样本 正样本 TP (True Positive) FN (False Negative) 负样本 FP (False Positive) TN (True Negative) 其次，介绍 5 个概率指标：①查准率P；②查全率/召回率R；③真正样本率TPR ；④假正样本率FPR；⑤准确率ACC。$$\begin{aligned}P &amp;=\frac{TP}{TP+FP} \R &amp;=\frac{TP}{TP+FN} \TPR &amp;=\frac{TP}{TP+FN}\FPR &amp;=\frac{FP}{TN+FP} \ACC &amp;= \frac{TP+TN}{TP+FN+FP+TN}\end{aligned}$$接着，明确 3 个关系：①TPR+FNR=1；②FPR+TNR=1；③对同一个系统来说，若TPR增加，则FPR也增加。 对于第③个关系的直观理解是：如果我们把更多的正样本识别为正样本，则我们一定会把更多的负样本识别为负样本。 P-R曲线：横坐标为R，纵坐标为P ROC曲线：横坐标为FPR，纵坐标为TPR AUC：也就是ROC曲线下的面积，是一个0到1之间的数，AUC越大说明系统性能越好。 EER ：也就是FPR=FNR的值，由于FNR=1-TPR，可以画一条从 (0,1) 到 (1,0) 的直线来找到交点。ERR越小系统性能越好。 2.10 SVM求解多分类问题二分类的多支持向量机求解多分类问题（假设共有K类），有如下2种策略： 1类对K-1类：需要构造K个支持向量机，存在训练样本不平衡的问题。 1类对另1类：需要构造K(K-1)/2个支持向量机，存在训练和测试时间过长的问题。 所以往往综合上述 2 种策略，构造树形分类器。如下图所示，8类只需要构造7个支持向量机，同时兼顾了样本数的平衡。值得一提的是，我们需要保证每个分类器区分的两类的差别是显著的，对于这一点我们可以利用聚类算法/决策树算法来解决。 ## 3 人工神经网络 3.1 神经元的数学模型人工智能的 2 个学派： 仿生学派：如人工神经网络 数理学派：如支持向量机 在生物神经网络中，每个神经元与其他神经元相连，当它”兴奋”时， 就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了 一个”阈值” ，那么它就会被激活，即 “兴奋 “起来，向其他神经元发送化学物质。 1943年，心理学家W.S.McCulloch和数理逻辑学家W.Pitts将上述情形抽象为图所示的简单模型，这就是一直沿用至今 的 “M-P神经元模型 “ 在这个模型中 ，神经元接收到来自 $n$ 个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将与神经元的阀值进行比较，然后通过”激活函数” 处理以产生神经元的输出。 [注释1]：为什么采用加权求和加上偏置的形式？如果假设神经元的输出 $y$ 是输入 $x_{i}$ 的函数 $f$，那么 $f$ 的一阶泰勒展开就是这样的形式$$\begin{aligned}y &amp;=f\left(x_{1}, x_{2}, \cdots x_{n}\right) \&amp; \approx f(0,0, \cdots 0)+\sum_{i=1}^{n}\left[\frac{\partial f}{\partial x_{i}} |(0,0, \cdots 0)\right] x_{i}+\ldots \&amp;=\sum_{i=1}^{m} \omega_{i} x_{i}+b\end{aligned}$$ 3.2 感知器算法及其意义感知器 (Perceptron) 由两层神经元组成， 输入层接收外界输入信号，输出层是M-P神经元。其数学表达式为：$$Y=\varphi(W^TX+b)$$感知器算法从 $(X,y )$ 对中通过学习获得 $W$ 和 $b$，步骤如下： 随机选择 $W$ 和 $b$ 取一个训练样本 $(X,y )$ 若 $W^{T}X+b&gt;0$，且 $y=-1$ 则：$W=W-X,\ b=b-1$ 若 $W^{T}X+b&lt;0$，且 $y=+1$ 则：$W=W+X,\ b=b+1$ 再取一个训练样本 $(X,y )$ 回到步骤 2 终止条件：直到所有输入输出对都不满足步骤 2 中的 2 个情形之一，退出循环 [证明1] 步骤 2 的合理性：以情形 1 为例，可以看到新值比原来至少减少了1，从而更加接近平衡$$\begin{aligned}&amp;W_{new}^{\mathrm{T}} X+b_{new} \=&amp;(W-X)s^{T} X+b-1 \=&amp;\left(W^{T} X+b\right)-\left(X^{T} X+1\right). \=&amp;\left(W^{T} X+b\right)-\left(|X|^{2}+1\right). \\leq&amp;\left(W^{T} X+b\right)-1.\end{aligned}$$[证明2] 步骤 4 的合理性：即证明感知器算法的收敛定理，过程与证明1类似，详见讲义4。将收敛定理用增广向量的形式进行描述：对于 $N$ 个增广向量，如果存在一个权重向量 $\omega_{opt}$ 使得对于每一个 $i$ 有 $\omega_{opt}^{T}x_{i}&gt;0$ ，运用上述感知器算法，必能够在有限步内，找到一个 $\omega$ 使得对所有 $i$ 有 $\omega^{T}x_{i}&gt;0$ 。该定理有 2 个注意点：①前提条件：训练集线性可分 (存在一个 $\omega_{opt}$ 使得 $\omega_{opt}^{T}x_{i}&gt;0$ )，所以感知器算法只能解决线性可分问题；②在有限步内找到的 $\omega$ 未必是 $\omega_{opt}$，所以其效果不如支持向量机。 感知器算法具有重要的历史意义： 提出了一套机器学习算法的框架：运用训练数据集 $(X_i,y_i)$ 求出待学习的参数 $\theta$，来寻找预测函数 $y=f(X;\theta)$ $$X \rightarrow f(X;\theta) \rightarrow Y$$ 相较于支持向量机这样的全局优化问题，消耗的计算资源和内存资源较少，是此类算法的先驱。 3.3 多层神经网络单层感知器的学习过程只在训练集线性可分的前提下收敛，若要解决非线性可分问题，就需考虑多层感知器/多层神经网络。比如两层感知器就可以解决非线性的异或问题： 花点时间明确一下概念 单层感知器：输入层+输出层 两层感知器/两层网络/单隐层网络：输入层+隐层+输出层 三层网络：输入层+隐层1+隐层2+输出层 [注释1] 为什么两层网络看起来有三层？因为输入层神经元仅仅是接受输入，不进行函数处理，所以通常称之为两层网络，为了避免歧义有时也称之为单隐层网络。 [注释2] 隐层神经元必须是功能神经元的必要性：不难证明，如果不加非线性函数，多层神经网络将会退化到一个神经元的M-P模型状态。 [注释3] 如果层与层之前的非线性函数是阶跃函数，理论上三层神经网络可以模拟任意的非线性函数。 3.4 梯度下降法为了使得神经网络训练的输出 $y$ 和标签 $Y$ 尽可能接近，将优化问题表示如下$$Minimize:E(\omega,b)=E_{(X,Y)}[(Y-y)^2]$$其中 $E_{(X,Y)}$ 是遍历训练样本及标签的数学期望。由于 $y$ 是 $(W,b)$ 的非凸函数，因此无法求到唯一的全局极值，而是用梯度下降法求解目标函数的局部极小值。 随机选取 $\omega$ 和 $b$ 的初始值 $(\omega^{(0)},b^{(0)})$ 应用迭代算法求目标函数的局部极值，其中 $\alpha$ 即学习率。 $$\begin{aligned}&amp;\omega^{(n+1)}=\omega^{(n)}-\left.\alpha \frac{\partial E}{\partial \omega}\right|{\omega^{(n)}, b^{(n)}}\&amp;b^{(n+1)}=b^{(n)}-\left.\alpha \frac{\partial E}{\partial b}\right|{\omega^{(n)}, b^{(n)}}\end{aligned}$$ 如果把梯度下降法应用到一个具体的例子中。 假设目标函数为：$$Minimize:E(\omega,b)=\frac{1}{2}(Y-y)^2$$那么待估计的参数有：$$(w_{11}, w_{12}, w_{21}, w_{22}, w_{1}, w_{2}, b_{1}, b_{2}, b_{3})$$梯度下降法相应就要求九个偏导数：$$\left(\frac{\partial E}{\partial \omega_{11}}, \frac{\partial E}{\partial \omega_{12}}, \frac{\partial E}{\partial \omega_{21}}, \frac{\partial E}{\partial \omega_{22}}, \frac{\partial E}{\partial \omega_{1}}, \frac{\partial E}{\partial \omega_{2}}, \frac{\partial E}{\partial b_{1}}, \frac{\partial E}{\partial b_{2}}, \frac{\partial E}{\partial b_{3}}\right)$$下一节内容讲的就是如何通过神经网络这种分层结构简化偏导数的计算过程。 3.5 后向传播算法后向传播算法框架 对神经网络每一层的各个神经元，随机选取相应的 $\omega$ 和 $b$ 前向计算，对于输入的训练数据，计算并保留每一层的输出值，直到计算出最后一层的输出 $y$ 设置目标函数 $E$，用后向传播算法对每一个 $\omega$ 和 $b$ 计算 $\frac{\partial E}{\partial \omega}, \frac{\partial E}{\partial b}$ 利用梯度下降法，更新 $\omega$ 和 $b$ 的值 回到第2步，不断循环，直到所有 $\left.\frac{\partial E}{\partial \omega}\right|{\omega^{(n)}, b^{(n)}}$，$\left.\frac{\partial E}{\partial b}\right|{\omega^{(n)}, b^{(n)}}$ 很小为止。退出循环。 后向传播算法核心 偏导数之间是相互关联的，根据链式求导法则，可以利用已经算出的偏导数求解其它偏导数。之所以称之为“后向”是因为这是一个从输出往输入推的过程，即先算出离输出较近的偏导数，再计算离输出较远的偏导数。 先考虑一个简单的例子，对应上一讲，将网络写成数学表达式。 $$ \begin{array}{l}a_{1}=w_{11} x_{1}+w_{12} x_{2}+b_{1} \\a_{2}=w_{21} x_{1}+w_{22} x_{2}+b_{2} \\z_{1}=\varphi\left(a_{1}\right) \\z_{2}=\varphi\left(a_{2}\right) \\y=w_{1} z_{1}+w_{2} z_{2}+b_{3}\end{array} $$ 首先求解如图标记的3个偏导数： $$ \begin{eqnarray*} &&\frac{\partial E}{\partial y}=y-Y \\ &&\frac{\partial E}{\partial a_{1}}=\frac{\partial E}{\partial y} \frac{\partial y}{\partial a_{1}}=\frac{\partial E}{\partial y} \frac{\partial y}{\partial z_{1}} \frac{d z_{1}}{d a_{1}}=\omega_{1}(y-Y) \varphi^{\prime}\left(a_{1}\right) \\ &&\frac{\partial E}{\partial a_{2}}=\frac{\partial E}{\partial y} \frac{\partial y}{\partial a_{2}}=\frac{\partial E}{\partial y} \frac{\partial y}{\partial z_{2}} \frac{d z_{2}}{d a_{2}}=\omega_{2}(y-Y) \varphi^{\prime}\left(a_{2}\right) \end{eqnarray*} $$ 求得上述枢纽函数的偏导数之后，由 $y=w_{1} z_{1}+w_{2} z_{2}+b_{3}$ 易得： $$ \begin{aligned} &\frac{\partial E}{\partial \omega_{1}}=\frac{\partial E}{\partial y} \frac{\partial y}{\partial \omega_{1}}=(y-Y) Z_{1}\\ &\frac{\partial E}{\partial \omega_{2}}=\frac{\partial E}{\partial y} \frac{\partial y}{\partial \omega_{2}}=(y-Y) Z_{2}\\ &\frac{\partial E}{\partial b_{3}}=\frac{\partial E}{\partial y} \frac{\partial y}{\partial b_{3}}=y-Y \end{aligned} $$ 由 $a_{1}=w_{11} x_{1}+w_{12} x_{2}+b_{1}$ 易得：$$\begin{aligned}&amp;\frac{\partial E}{\partial \omega_{11}}=\frac{\partial E}{\partial a_{1}} \frac{\partial a_{1}}{\partial \omega_{11}}=\omega_{1}(y-Y) \varphi^{\prime}\left(a_{1}\right) x_{1} \&amp;\frac{\partial E}{\partial \omega_{12}}=\frac{\partial E}{\partial a_{1}} \frac{\partial a_{1}}{\partial \omega_{12}}=\omega_{1}(y-Y) \varphi^{\prime}\left(a_{1}\right) x_{2} \&amp;\frac{\partial E}{\partial b_{1}}=\frac{\partial E}{\partial a_{1}} \frac{\partial a_{1}}{\partial b_{1}}=\omega_{1}(y-Y) \varphi^{\prime}\left(a_{1}\right)\end{aligned}$$ 由 $a_{2}=w_{21} x_{1}+w_{22} x_{2}+b_{2}$ 易得：$$\begin{aligned}&amp;\frac{\partial E}{\partial \omega_{21}}=\frac{\partial E}{\partial a_{2}} \frac{\partial a_{2}}{\partial \omega_{21}}=\omega_{2}(y-Y) \varphi^{\prime}\left(a_{2}\right) x_{1} \&amp;\frac{\partial E}{\partial \omega_{22}}=\frac{\partial E}{\partial a_{2}} \frac{\partial a_{2}}{\partial \omega_{22}}=\omega_{2}(y-Y) \varphi^{\prime}\left(a_{2}\right) x_{2} \&amp;\frac{\partial E}{\partial b_{2}}=\frac{\partial E}{\partial a_{2}} \frac{\partial a_{2}}{\partial b_{2}}=\omega_{2}(y-Y) \varphi^{\prime}\left(a_{2}\right)\end{aligned}$$至此求得了九个偏导数。 接下来，我们考虑更一般的情况。将神经网络写成矩阵形式的如下表示式。其中 ①网络共有 $l$ 层；② $z^{(k)},a^{(k)},b^{(k)}$ 为向量，用 $z_{i}^{(k)},a_{i}^{(k)},b_{i}^{(k)}$ 表示其第 $i$ 个分量；③输出 $y$ 可以是向量，用 $y_i$ 表示其第 $i$ 个分量。$$\begin{array}{l}x=a^{(0)} \Rightarrow z^{(1)}=w^{(1)} a^{(0)}+b^{(1)} \Rightarrow a^{(1)}=\varphi\left(z^{(1)}\right) \ \quad \Rightarrow z^{(2)}=w^{(2)} a^{(1)}+b^{(2)} \Rightarrow a^{(2)}=\varphi\left(z^{(2)}\right) \cdots \ \cdots \Rightarrow z^{(m)}=w^{(m)} a^{(m-1)}+b^{(m)} \Rightarrow a^{(m)}=\varphi\left(z^{(m)}\right) \cdots \ \quad \cdots \Rightarrow z^{(l)}=w^{(l)} a^{(l-1)}+b^{(l)} \Rightarrow y=a^{(l)}=\varphi\left(z^{(l)}\right)\end{array}$$同样假设目标函数为：$$Minimize:E(\omega,b)=\frac{1}{2}(Y-y)^2$$设置枢纽变量为：$$\delta_{i}^{(\mathrm{m})}=\frac{\partial E}{\partial z_{i}^{(m)}}$$最后一层为：$$\delta_{i}^{(l)}=\frac{\partial E}{\partial z_{i}^{(l)}}=\frac{\partial E}{\partial y_{i}} \cdot \frac{\partial y_{i}}{\partial z_{i}^{(l)}}=\left(y_{i}-Y_{i}\right) \varphi^{\prime}\left(z_{i}^{(l)}\right)$$通过第 $m+1$ 层推导到第 $m$ 层：$$\begin{eqnarray} \delta_{i}^{(m)}=\frac{\partial E}{\partial z_{i}^{(m)}} &amp;&amp;=\sum_{j=1}^{S_{m+1}} \frac{\partial E}{\partial z_{j}^{(m+1)}} \cdot \frac{\partial z_{j}^{(m+1)}}{\partial z_{i}^{(m)}} \&amp;&amp;=\sum_{j=1}^{S_{m+1}} \delta_{j}^{(m+1)} \frac{\partial z_{j}^{(m+1)}}{\partial z_{i}^{(m)}} \&amp;&amp;=\left[\sum_{j=1}^{S_{m+1}} \delta_{j}^{(m+1)} W_{j i}^{(m+1)}\right] \varphi^{\prime}\left(Z_{i}^{(m)}\right) \tag{3.5.1}\end{eqnarray}$$其中第2行到第3行的推导：$$\begin{aligned} \frac{\partial z_{j}^{(m+1)}}{\partial z_{i}^{(m)}} &amp;=\frac{\partial z_{j}^{(m+1)}}{\partial \mathbf{a}{i}^{(m)}} \frac{\partial a{j}^{(m)}}{\partial z_{i}^{(m)}} \ &amp;=W_{j i}^{(m+1)} \varphi^{\prime}\left(Z_{i}^{(m)}\right) \end{aligned}$$式（3.5.1）表明我们可以通过 $\delta_{i}^{(l)}$ 逐层向前递推 $\delta_{i}^{(m)}$，也易得：$$\begin{eqnarray}&amp;&amp;\frac{\partial E}{\partial W_{j i}^{(m)}}=\delta_{j}^{(m)} \cdot a_{i}^{(m-1)} \tag{3.5.2}\&amp;&amp;\frac{\partial E}{\partial b_{i}^{(m)}}=\delta_{i}^{(m)}\tag{3.5.3}\end{eqnarray}$$ 3.6 三个改进 非线性函数的改进 问题：如果层与层之间的函数为阶跃函数，那么求导就会出现问题。 改进：常用的非线性函数有 目标函数的改进 问题： 改进：常采用基于softmax和cross-entropy的目标函数。 参数更新的改进 问题：如果每输入一个样本就更新参数，网络训练速度过慢；单一数据带来的随机性，使得算法收敛缓慢 改进：采用随机梯度下降法(SGD)。输入一批样本(batch或mini-batch)，求出这些样本的梯度平均值后根据这个平均值改变参数。在神经网络训练中，batch的样本数(batchsize)大致设置为50~200不等。对于所有训练数据，根据batch size分割为各个不同的batch。一个epoch指的是按照batch遍历所有训练样本一次。实际训练中，往往训练多个epoch，对于每一个epoch需要随机打乱所有训练样本的次序，增加batch中训练样本的随机性。 5 强化学习5.1 传统强化学习算法Q-Learning 算法 epsilion-greedy 算法 5.2 深度强化学习蒙特卡洛算法：是利用一个回合结束后得到的奖励来更新当前的Q值； 时序差分更新：希望可以尽早的更新Q值，而不是只有等到一个回合结束之后才能更新。 两者更新公式的常用形式分别如下： $Q(s_t,a_t)$ 的值表示 agent 在状态 $s_t$ 下，执行动作 $a_t$ 后，沿着当前策略走下去后所能得到的累积奖励的期望，是对奖励的一个估计值。所以从处理奖励值的角度看：蒙特卡洛算法中走完一个回合后得到的G是真实的奖励值，而时序差分学习则是用估计的奖励值替代真实的奖励值来更新。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Zotero简明使用指南]]></title>
    <url>%2F2020%2F01%2F08%2FZotero%E7%AE%80%E6%98%8E%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[文献管理工具 下载与基本设置 下载官网下载Zotero和Zotero Connector。前者是管理文献的本体；后者是用于抓取条目和相关附件的浏览器插件。 设置同步Zotero本身自带同步功能，但是自带空间有限，故可以使用webdav连接到其他网盘，以坚果云为例：如何在Zotero中设置webdav连接到坚果云？ 设置ZotfileZotfile是一款插件，配合Zotero使用可以更好地管理（批量命名和移除等）文献附件：下载和设置。 其它功能 导出参考文献（Word/Latex）若不使用插件，❶直接拖拽条目至文本编辑器/使用快捷键即可实现单条目的快速复制；❷在Zotero中选取所需条目，右键选择由所选条目创建引文目录即可实现多条目的快速复制。若使用插件，以Word为例，在成功安装插件的前提下Word菜单栏中会出现Zotero选项卡，可方便地添加引用和参考文献。 Papership（ipad/iphone端）Zotero只有PC端应用，配合Papership使用可以弥补该不足。用Zotero账户登录Papership应用，并设置Zotero File Hosting（与步骤1.2设置同步类似）就可以在平板和手机上同步阅读文献了。]]></content>
      <categories>
        <category>指南</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[语义分割方法整理]]></title>
    <url>%2F2019%2F09%2F23%2FSemantic-Segmentation%2F</url>
    <content type="text"><![CDATA[持续更新 Basis FCN [FCN] Fully Convolutional Networks for Semantic Segmentation DeepLab [DeepLab v1] Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs [DeepLab v2] DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs [DeepLab v3] Rethinking Atrous Convolution for Semantic Image Segmentation [DeepLab v3+] Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation Encoder-decoder Architecture [U-Net] U-Net: Convolutional Networks for Biomedical Image Segmentation [SegNet] SegNet: A Deep Convolutional Encoder-Decoder Architecture for Scene Segmentation [DeconvNet] Learning Deconvolution Network for Semantic Segmentation [RefineNet] RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation MethodCRF [CRFasRNN] Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials [MRF] Semantic Image Segmentation via Deep Parsing Network [GRF] Fast, Exact and Multi-Scale Inference for Semantic Image Segmentation with Deep Gaussian CRFs Atrous/Dilated Convolution [DUC-HDC] Understanding Convolution for Semantic Segmentation [DRN] Dilated Residual Networks Smoothed Dilated Convolutions for Improved Dense Prediction Efficient Smoothing of Dilated Convolutions for Image Segmentation [FastFCN] FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation Context Aggregation Pooling [ParseNet] ParseNet: Looking Wider to See Better [PSPNet] Pyramid Scene Parsing Network [DenseASPP] DenseASPP for Semantic Segmentation in Street Scenes [VortexPooling] Vortex Pooling: Improving Context Representation in Semantic Segmentation Large Kernel [GCN] Large Kernel Matters — Improve Semantic Segmentation by Global Convolutional Network [ExFuse] ExFuse: Enhancing Feature Fusion for Semantic Segmentation Attention Mechanism Channel Reweighting [DFN] Learning a Discriminative Feature Network for Semantic Segmentation [EncNet] Context Encoding for Semantic Segmentation[ [SENet] Squeeze-and-Excitation Networks Pyramid Attention Network for Semantic Segmentation Spatial Attention [OCNet] OCNet: Object Context Network for Scene Parsing [DANet] Dual Attention Networks for Multimodal Reasoning and Matching [PSANet] PSANet: Point-wise Spatial Attention Network for Scene Parsing [CCNet] CCNet: Criss-Cross Attention for Semantic Segmentation Graph Convolution [GloRe] Graph-Based Global Reasoning Networks Beyond Grids: Learning Graph Representations for Visual Recognition Real-time MethodConvolution Factorization [ENet] ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation [ERFNet] ERFNet: Efficient Residual Factorized ConvNet for Real-Time Semantic Segmentation [ESPNet] ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation [ESNet] ESNet: An Efficient Symmetric Network for Real-time Semantic Segmentation [LEDNet] LEDNet: A Lightweight Encoder-Decoder Network for Real-Time Semantic Segmentation [DABNet] DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation Multi-branch [ICNet] ICNet for Real-Time Semantic Segmentation on High-Resolution Images [ContextNet] ContextNet: Exploring Context and Detail for Semantic Segmentation in Real-time [BiSeNet] BiSeNet: Bilateral Segmentation Network for Real-Time Semantic Segmentation Reference 语义分割论文整理 [blog] Survey on semantic segmentation using deep learning techniques [paper]]]></content>
      <categories>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[道路场景语义分割]]></title>
    <url>%2F2019%2F07%2F11%2F%E9%81%93%E8%B7%AF%E5%9C%BA%E6%99%AF%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%2F</url>
    <content type="text"><![CDATA[持续更新 Datasets Apolloscape Scene Parsing BDD100k CamVid Cityscapes Daimler Urban Segmentation Kitti Mapillary Vistas Method Method Cityscapes(%) CamVid(%) Publication FCN-8s 65.3 CVPR2015 SegNet 50.2 arXiv15 DeepLab v2 70.4 PAMI2018 G-FRNet 68.0 CVPR2017 FRRN B 71.8 CVPR2017 RefineNet 73.6 CVPR2017 GCN 76.9 CVPR2017 TKCN 79.5 ICME2019 DUC-HDC 80.1 WACV2018 PSANet 80.1 ECCV2018 PSPNet 80.2 CVPR2017 DDSC 70.9 CVPR2018 DFN 80.3 CVPR2018 DenseASPP 80.6 CVPR2018 LDN 80.6 78.1 arXiv19 GloRe 80.9 CVPR2019 OCNet 81.2 arXiv18 DeepLab v3 81.3 arXiv17 CCNet 81.4 arXiv18 DAN 81.5 CVPR2019 HRNetV2 81.6 arXiv19 CaseNet 81.9 arXiv19 DeepLab v3+ 82.1 ECCV2018 GFF 82.3 arXiv19 DPC 82.7 NIPS2018 GSCNN 82.8 ICCV2019 Real-time Method Method WxH mIOU(%) FPS GFLOPs Param(M) ENet 1920x1080 58.3 21.6 3.83 0.37 SQ 2048x1024 59.8 - - - TwoColumn 1024x512 72.9 14.7 - - CGNet 2048x1024 64.8 17.6 6 0.5 ESPNet - 60.3 4 - 0.4 ERFNet - 68 - - - ICNet 2048x1024 69.5 30.3 - - BiSeNet 1536x768 68.4 105.8 2.9 5.8 1536x768 74.7 65.5 10.8 49 ESNet - 70.7 63 - 1.66 DFANet 1024x1024 71.3 100 3.4 7.8 LEDNet 1024x512 70.1 71 - 0.94 DABNet 1024x512 70.1 104.2 - 0.76 SqueezeNAS 1024x512 72.5 - - 1.9 *上表为文献中各方法在Cityscapes上的性能]]></content>
      <categories>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一个测试]]></title>
    <url>%2F2018%2F05%2F11%2F%E4%B8%80%E4%B8%AA%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[ヾ(๑╹◡╹)ﾉ”]]></content>
      <categories>
        <category>胡言</category>
      </categories>
  </entry>
</search>
